# %% [markdown]
# # Inference
# 
# You will probably use a `Submission.ipynb` kernel to run all the predictions. After training a YOLOv5 based object detector -> head to the artifacts page and download the best model -> upload the model as a Kaggle dataset -> Use it with the submission folder. 
# 
# > üìç Note that you might have to clone the YOLOv5 repository in a Kaggle dataset as well. 
# 
# In this section, I will show you how you can do the inference and modify the predicted bounding box coordinates.

# %%
# TEST_PATH = '/kaggle/input/siim-covid19-resized-to-256px-jpg/test/' # absolute path
TEST_PATH = '../input/test/' # absolute path

# %% [markdown]
# Since I am training the model in this kernel itself, I will not be using the method that I have described above. The best model is saved in the directory `project_name/exp*/weights/best.pt`. In `exp*`, * can be 1, 2, etc. 

# %%
# MODEL_PATH = 'kaggle-siim-covid/exp/weights/best.pt'
MODEL_PATH = '../models/exp1/best.pt'

# %% [markdown]
# ```
# --weights {MODEL_PATH} \ # path to the best model.
# --source {TEST_PATH} \ # absolute path to the test images.
# --img {IMG_SIZE} \ # Size of image
# --conf 0.281 \ # Confidence threshold (default is 0.25)
# --iou-thres 0.5 \ # IOU threshold (default is 0.45)
# --max-det 3 \ # Number of detections per image (default is 1000) 
# --save-txt \ # Save predicted bounding box coordinates as txt files
# --save-conf # Save the confidence of prediction for each bounding box
# ```

# %%
get_ipython().system('python detect.py --weights {MODEL_PATH}                   --source {TEST_PATH}                   --img {IMG_SIZE}                   --conf 0.281                   --iou-thres 0.5                   --max-det 3                   --save-txt                   --save-conf')

# %% [markdown]
# ### How to find the confidence score?
# 
# 1. First first the [W&B run page](https://wandb.ai/ayush-thakur/kaggle-siim-covid/runs/jbt74n7q) generated by training the YOLOv5 model. 
# 
# 2. Go to the media panel -> click on the F1_curve.png file to get a rough estimate of the threshold -> go to the Bounding Box Debugger panel and interactively adjust the confidence threshold. 
# 
# %% [markdown]
# > üìç The bounding box coordinates are saved as text file per image name. It is saved in this directory `runs/detect/exp3/labels`. 

# %%
PRED_PATH = 'runs/detect/exp3/labels'


# %%
# Visualize predicted coordinates.

# %% [markdown]
# > üìç Note: 1 is class id (opacity), the first four float numbers are `x_center`, `y_center`, `width` and `height`. The final float value is `confidence`.

# %%
prediction_files = os.listdir(PRED_PATH)
print('Number of test images predicted as opaque: ', len(prediction_files))

# %% [markdown]
# > üìç Out of 1263 test images, 583 were predicted with `opacity` label and thus we have that many prediction txt files.
# %% [markdown]
# # Submission
# 
# In this section, I will show how you can use YOLOv5 as object detector and prepare `submission.csv` file.

# %%
# The submisison requires xmin, ymin, xmax, ymax format. 
# YOLOv5 returns x_center, y_center, width, height
def correct_bbox_format(bboxes):
    correct_bboxes = []
    for b in bboxes:
        xc, yc = int(np.round(b[0]*IMG_SIZE)), int(np.round(b[1]*IMG_SIZE))
        w, h = int(np.round(b[2]*IMG_SIZE)), int(np.round(b[3]*IMG_SIZE))

        xmin = xc - int(np.round(w/2))
        xmax = xc + int(np.round(w/2))
        ymin = yc - int(np.round(h/2))
        ymax = yc + int(np.round(h/2))
        
        correct_bboxes.append([xmin, xmax, ymin, ymax])
        
    return correct_bboxes

# Read the txt file generated by YOLOv5 during inference and extract 
# confidence and bounding box coordinates.
def get_conf_bboxes(file_path):
    confidence = []
    bboxes = []
    with open(file_path, 'r') as file:
        for line in file:
            preds = line.strip('\n').split(' ')
            preds = list(map(float, preds))
            confidence.append(preds[-1])
            bboxes.append(preds[1:-1])
    return confidence, bboxes


# %%
# Read the submisison file
# sub_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')
sub_df = pd.read_csv('../input/sample_submission.csv')
sub_df.tail()


# %%
# Prediction loop for submission
predictions = []

for i in tqdm(range(len(sub_df))):
    row = sub_df.loc[i]
    id_name = row.id.split('_')[0]
    id_level = row.id.split('_')[-1]
    
    if id_level == 'study':
        # do study-level classification
        predictions.append("Negative 1 0 0 1 1") # dummy prediction
        
    elif id_level == 'image':
        # we can do image-level classification here.
        # also we can rely on the object detector's classification head.
        # for this example submisison we will use YOLO's classification head. 
        # since we already ran the inference we know which test images belong to opacity.
        if f'{id_name}.txt' in prediction_files:
            # opacity label
            confidence, bboxes = get_conf_bboxes(f'{PRED_PATH}/{id_name}.txt')
            bboxes = correct_bbox_format(bboxes)
            pred_string = ''
            for j, conf in enumerate(confidence):
                pred_string += f'opacity {conf} ' + ' '.join(map(str, bboxes[j])) + ' '
            predictions.append(pred_string[:-1]) 
        else:
            predictions.append("None 1 0 0 1 1")


# %%
sub_df['PredictionString'] = predictions
# sub_df.to_csv('submission.csv', index=False)