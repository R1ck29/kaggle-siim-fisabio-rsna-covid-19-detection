{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018717,
     "end_time": "2021-06-07T14:26:39.313615",
     "exception": false,
     "start_time": "2021-06-07T14:26:39.294898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "https://www.kaggle.com/laxmikantnishad/covid-19-2-para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_local=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-06-07T14:26:39.367375Z",
     "iopub.status.busy": "2021-06-07T14:26:39.366847Z",
     "iopub.status.idle": "2021-06-07T14:27:49.091397Z",
     "shell.execute_reply": "2021-06-07T14:27:49.090810Z",
     "shell.execute_reply.started": "2021-06-07T13:10:42.471944Z"
    },
    "papermill": {
     "duration": 69.759074,
     "end_time": "2021-06-07T14:27:49.091560",
     "exception": false,
     "start_time": "2021-06-07T14:26:39.332486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not is_local:\n",
    "    !conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n",
    "    !conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n",
    "    !conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n",
    "    !conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n",
    "    !conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n",
    "    !conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-07T14:27:49.169167Z",
     "iopub.status.busy": "2021-06-07T14:27:49.168392Z",
     "iopub.status.idle": "2021-06-07T14:27:49.175918Z",
     "shell.execute_reply": "2021-06-07T14:27:49.175484Z",
     "shell.execute_reply.started": "2021-06-07T13:11:54.060955Z"
    },
    "papermill": {
     "duration": 0.04742,
     "end_time": "2021-06-07T14:27:49.176025",
     "exception": false,
     "start_time": "2021-06-07T14:27:49.128605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035874,
     "end_time": "2021-06-07T14:27:49.248235",
     "exception": false,
     "start_time": "2021-06-07T14:27:49.212361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "（1）dcm to .png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T14:27:49.326735Z",
     "iopub.status.busy": "2021-06-07T14:27:49.325929Z",
     "iopub.status.idle": "2021-06-07T14:27:49.479277Z",
     "shell.execute_reply": "2021-06-07T14:27:49.478742Z",
     "shell.execute_reply.started": "2021-06-07T13:11:54.076056Z"
    },
    "papermill": {
     "duration": 0.19517,
     "end_time": "2021-06-07T14:27:49.479448",
     "exception": false,
     "start_time": "2021-06-07T14:27:49.284278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_xray(path, voi_lut = True, fix_monochrome = True):\n",
    "    import pydicom\n",
    "    from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n",
    "    dicom = pydicom.read_file(path)\n",
    "    \n",
    "    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n",
    "    # \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        data = dicom.pixel_array\n",
    "               \n",
    "    # depending on this value, X-ray may look inverted - fix that:\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        data = np.amax(data) - data\n",
    "        \n",
    "    data = data - np.min(data)\n",
    "    data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "        \n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T14:27:49.556067Z",
     "iopub.status.busy": "2021-06-07T14:27:49.555375Z",
     "iopub.status.idle": "2021-06-07T14:27:49.558019Z",
     "shell.execute_reply": "2021-06-07T14:27:49.557605Z",
     "shell.execute_reply.started": "2021-06-07T13:11:54.338902Z"
    },
    "papermill": {
     "duration": 0.04271,
     "end_time": "2021-06-07T14:27:49.558118",
     "exception": false,
     "start_time": "2021-06-07T14:27:49.515408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n",
    "    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image\n",
    "    im = Image.fromarray(array)\n",
    "    \n",
    "    if keep_ratio:\n",
    "        im.thumbnail((size, size), resample)\n",
    "    else:\n",
    "        im = im.resize((size, size), resample)\n",
    "    \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T14:27:49.708403Z",
     "iopub.status.busy": "2021-06-07T14:27:49.707554Z",
     "iopub.status.idle": "2021-06-07T14:35:52.671653Z",
     "shell.execute_reply": "2021-06-07T14:35:52.671027Z",
     "shell.execute_reply.started": "2021-06-07T13:11:54.347352Z"
    },
    "papermill": {
     "duration": 483.005821,
     "end_time": "2021-06-07T14:35:52.671838",
     "exception": false,
     "start_time": "2021-06-07T14:27:49.666017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_test_images():\n",
    "    split = 'test'\n",
    "    save_dir = f'./{split}/'\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    save_dir = f'./{split}/study/'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):\n",
    "        for file in filenames:\n",
    "            # set keep_ratio=True to have original aspect ratio\n",
    "            xray = read_xray(os.path.join(dirname, file))\n",
    "            im = resize(xray, size=512)  \n",
    "            study = dirname.split('/')[-2] + '_study.png'\n",
    "            #study = dirname.split('/')[-2] + '_study'\n",
    "            im.save(os.path.join(save_dir, study))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T14:35:52.976585Z",
     "iopub.status.busy": "2021-06-07T14:35:52.975833Z",
     "iopub.status.idle": "2021-06-07T14:35:52.978886Z",
     "shell.execute_reply": "2021-06-07T14:35:52.978389Z",
     "shell.execute_reply.started": "2021-06-07T13:21:23.341760Z"
    },
    "papermill": {
     "duration": 0.044069,
     "end_time": "2021-06-07T14:35:52.979002",
     "exception": false,
     "start_time": "2021-06-07T14:35:52.934933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys; \n",
    "\n",
    "package_paths = [\n",
    "    '../input/image-fmix/FMix-master'                            #FMix是一种数据增强方法（最近比较火的一种）\n",
    "]\n",
    "\n",
    "if not is_local:\n",
    "    package_paths.append('../input/pytorch-image-models/pytorch-image-models-master') #导入pytorch模型\n",
    "\n",
    "for pth in package_paths:\n",
    "    sys.path.append(pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T14:35:53.060799Z",
     "iopub.status.busy": "2021-06-07T14:35:53.060041Z",
     "iopub.status.idle": "2021-06-07T14:35:56.191146Z",
     "shell.execute_reply": "2021-06-07T14:35:56.190245Z",
     "shell.execute_reply.started": "2021-06-07T13:21:23.357477Z"
    },
    "papermill": {
     "duration": 3.17552,
     "end_time": "2021-06-07T14:35:56.191280",
     "exception": false,
     "start_time": "2021-06-07T14:35:53.015760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import cv2\n",
    "from skimage import io\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import timm\n",
    "import sklearn\n",
    "import warnings\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "from fmix import sample_mask, make_low_freq_image, binarise_mask\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T14:35:56.274360Z",
     "iopub.status.busy": "2021-06-07T14:35:56.273785Z",
     "iopub.status.idle": "2021-06-07T14:35:56.309341Z",
     "shell.execute_reply": "2021-06-07T14:35:56.310081Z",
     "shell.execute_reply.started": "2021-06-07T13:21:26.649691Z"
    },
    "papermill": {
     "duration": 0.081302,
     "end_time": "2021-06-07T14:35:56.310213",
     "exception": false,
     "start_time": "2021-06-07T14:35:56.228911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# COMPETITION_NAME = \"siimcovid19-512-img-png-600-study-png\"\n",
    "# load_dir = f\"/kaggle/input/{COMPETITION_NAME}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T14:35:56.399361Z",
     "iopub.status.busy": "2021-06-07T14:35:56.398786Z",
     "iopub.status.idle": "2021-06-07T14:35:56.403580Z",
     "shell.execute_reply": "2021-06-07T14:35:56.403972Z",
     "shell.execute_reply.started": "2021-06-07T13:21:26.699667Z"
    },
    "papermill": {
     "duration": 0.056177,
     "end_time": "2021-06-07T14:35:56.404094",
     "exception": false,
     "start_time": "2021-06-07T14:35:56.347917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.rename(columns={'Negative for Pneumonia':'0','Typical Appearance':'1',\"Indeterminate Appearance\":'2',\n",
    "#                    \"Atypical Appearance\":\"3\"}, inplace=True)\n",
    "# # one-hot\n",
    "# labels = []\n",
    "# def get_label(row):\n",
    "#     for c in df.columns:\n",
    "#         if row[c]==1:\n",
    "#             labels.append(int(c))\n",
    "# df.apply(get_label, axis=1)\n",
    "# print(\"label modified\")\n",
    "\n",
    "# labels = {'label':labels}\n",
    "# study_label = pd.DataFrame(labels)\n",
    "# train_study = pd.concat([df, study_label], axis = 1)\n",
    "# #print(train_study)\n",
    "# del train_study ['0'];del train_study ['1'];del train_study ['2'];del train_study ['3']\n",
    "# train_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T14:35:57.025074Z",
     "iopub.status.busy": "2021-06-07T14:35:57.023700Z",
     "iopub.status.idle": "2021-06-07T14:35:57.026659Z",
     "shell.execute_reply": "2021-06-07T14:35:57.026219Z",
     "shell.execute_reply.started": "2021-06-07T13:21:26.944162Z"
    },
    "papermill": {
     "duration": 0.045812,
     "end_time": "2021-06-07T14:35:57.026765",
     "exception": false,
     "start_time": "2021-06-07T14:35:56.980953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CFG = {\n",
    "#     'fold_num': 5,\n",
    "#     'seed': 719,\n",
    "#     'model_arch': 'tf_efficientnet_b4_ns',\n",
    "#     'img_size': 512,\n",
    "#     'epochs': 10,\n",
    "#     'train_bs': 32,\n",
    "#     'valid_bs': 32,\n",
    "#     'lr': 1e-4,\n",
    "#     'num_workers': 4,\n",
    "#     'accum_iter': 1, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "#     'verbose_step': 1,\n",
    "#     'device': 'cuda:0',\n",
    "#     'tta': 3,\n",
    "#     'used_epochs': [53,55,56,59],\n",
    "#     'weights': [1,1,1,1]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T14:35:57.109154Z",
     "iopub.status.busy": "2021-06-07T14:35:57.107765Z",
     "iopub.status.idle": "2021-06-07T14:35:57.109966Z",
     "shell.execute_reply": "2021-06-07T14:35:57.110380Z",
     "shell.execute_reply.started": "2021-06-07T13:21:26.953780Z"
    },
    "papermill": {
     "duration": 0.04566,
     "end_time": "2021-06-07T14:35:57.110499",
     "exception": false,
     "start_time": "2021-06-07T14:35:57.064839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    #print(im_rgb)\n",
    "    return im_rgb\n",
    "\n",
    "#img = get_img('../input/siim-covid19-detection/test/00188a671292/3eb5a506ccf3/3dcdfc352a06.dcm')\n",
    "#plt.imshow(img)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T14:35:57.194175Z",
     "iopub.status.busy": "2021-06-07T14:35:57.193006Z",
     "iopub.status.idle": "2021-06-07T14:35:57.195334Z",
     "shell.execute_reply": "2021-06-07T14:35:57.195733Z",
     "shell.execute_reply.started": "2021-06-07T13:21:26.963700Z"
    },
    "papermill": {
     "duration": 0.048032,
     "end_time": "2021-06-07T14:35:57.195847",
     "exception": false,
     "start_time": "2021-06-07T14:35:57.147815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, df, data_root, transforms=None, output_label=True\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.id_col_name = 'study_id'\n",
    "        self.transforms = transforms\n",
    "        self.data_root = data_root\n",
    "        self.output_label = output_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # get labels\n",
    "        if self.output_label:\n",
    "            target = self.df.iloc[index]['class_id']\n",
    "        \n",
    "        tempstr = self.df.iloc[index][self.id_col_name][-3:]\n",
    "        if tempstr == 'png':\n",
    "            path = \"{}/{}\".format(self.data_root, self.df.iloc[index][self.id_col_name])\n",
    "        else:\n",
    "            path = \"{}/{}\".format(self.data_root, self.df.iloc[index][self.id_col_name])+'.png'\n",
    "        \n",
    "        img  = get_img(path)\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "            \n",
    "        # do label smoothing\n",
    "        if self.output_label == True:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T14:35:57.283554Z",
     "iopub.status.busy": "2021-06-07T14:35:57.278200Z",
     "iopub.status.idle": "2021-06-07T14:35:57.924887Z",
     "shell.execute_reply": "2021-06-07T14:35:57.924396Z",
     "shell.execute_reply.started": "2021-06-07T13:21:26.977496Z"
    },
    "papermill": {
     "duration": 0.6915,
     "end_time": "2021-06-07T14:35:57.925007",
     "exception": false,
     "start_time": "2021-06-07T14:35:57.233507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n",
    ")\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def get_train_transforms():\n",
    "    return Compose([\n",
    "            RandomResizedCrop(cfg['img_size'], cfg['img_size']),\n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            ShiftScaleRotate(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            CoarseDropout(p=0.5),\n",
    "            Cutout(p=0.5),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "  \n",
    "        \n",
    "def get_valid_transforms():\n",
    "    return Compose([\n",
    "            CenterCrop(cfg['img_size'], cfg['img_size'], p=1.),\n",
    "            Resize(cfg['img_size'], cfg['img_size']),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "\n",
    "def get_inference_transforms():\n",
    "    return Compose([\n",
    "            RandomResizedCrop(cfg['img_size'], cfg['img_size']),\n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T14:35:58.005570Z",
     "iopub.status.busy": "2021-06-07T14:35:58.004905Z",
     "iopub.status.idle": "2021-06-07T14:35:58.008576Z",
     "shell.execute_reply": "2021-06-07T14:35:58.008174Z",
     "shell.execute_reply.started": "2021-06-07T13:21:27.618781Z"
    },
    "papermill": {
     "duration": 0.045722,
     "end_time": "2021-06-07T14:35:58.008682",
     "exception": false,
     "start_time": "2021-06-07T14:35:57.962960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, n_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T14:35:58.088715Z",
     "iopub.status.busy": "2021-06-07T14:35:58.088044Z",
     "iopub.status.idle": "2021-06-07T14:35:58.091322Z",
     "shell.execute_reply": "2021-06-07T14:35:58.091699Z",
     "shell.execute_reply.started": "2021-06-07T13:21:27.634990Z"
    },
    "papermill": {
     "duration": 0.045976,
     "end_time": "2021-06-07T14:35:58.091818",
     "exception": false,
     "start_time": "2021-06-07T14:35:58.045842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_one_epoch(model, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    image_preds_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        \n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        \n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub_df(testid, tst_preds):\n",
    "    sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\n",
    "    for i in range(len(test)):\n",
    "        for j in range(len(test)):\n",
    "            a = test.loc[i,'id'].split('.')[0]\n",
    "            b = sub_df.loc[j,'id']\n",
    "            if a==b:\n",
    "                negative, typical, indeterminate, atypical = str(tst_preds[i][0]),str(tst_preds[i][1]),str(tst_preds[i][2]),str(tst_preds[i][3]),\n",
    "                sub_df.loc[j,'PredictionString'] = f'negative {negative} 0 0 1 1 typical {typical} 0 0 1 1 indeterminate {indeterminate} 0 0 1 1 atypical {atypical} 0 0 1 1'\n",
    "    return sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(cfg, is_local):\n",
    "    if is_local:\n",
    "        print('Inference on Validation dataset')\n",
    "    else:\n",
    "        print('Inference on Test dataset')\n",
    "\n",
    "    seed_everything(cfg['seed'])\n",
    "    # folds = StratifiedKFold(n_splits=CFG['fold_num']).split(np.arange(train_study.shape[0]), train_study.label.values)\n",
    "\n",
    "    if is_local:\n",
    "        model_dir = f'../models/{cfg[\"exp_id\"]}/'\n",
    "        train_img_path = '../input/siimcovid19-512-img-png-600-study-png/study/'\n",
    "        test_img_path = './test/study/'\n",
    "        train_csv_path = f'../input/siim_covid19_train/{cfg[\"train_csv_name\"]}'\n",
    "        train = pd.read_csv(train_csv_path)\n",
    "    else:\n",
    "        model_dir = f'../input/siim_covid19_studyclass_models/{cfg[\"exp_id\"]}/'\n",
    "        train_img_path = '../input/siimcovid19-512-img-png-600-study-png/study/'\n",
    "        test_img_path = './test/study/'\n",
    "        train_csv_path = f'../input/siim_covid19_train/{cfg[\"train_csv_name\"]}'\n",
    "        prepare_test_images()\n",
    "    \n",
    "    accs = []\n",
    "    # for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "    for idx, fold in enumerate(range(cfg['fold_num'])):\n",
    "        # train_df = train[train['fold'] != fold]\n",
    "        valid_df = train[train['fold'] == fold]\n",
    "        # we'll train fold 0 first\n",
    "#         if fold > 0:\n",
    "#             break \n",
    "\n",
    "        print('Inference fold {} started'.format(fold))\n",
    "\n",
    "        if is_local:\n",
    "            # valid_ = train_study.loc[val_idx,:].reset_index(drop=True)\n",
    "            #print('valid_',valid_)\n",
    "            valid_ds = CassavaDataset(valid_df, train_img_path, transforms=get_inference_transforms(), output_label=False)\n",
    "            val_loader = torch.utils.data.DataLoader(\n",
    "                valid_ds, \n",
    "                batch_size=cfg['valid_bs'],\n",
    "                num_workers=cfg['num_workers'],\n",
    "                shuffle=False,\n",
    "                pin_memory=False,\n",
    "            )\n",
    "            data_loader = val_loader\n",
    "        else:\n",
    "            test = pd.DataFrame()\n",
    "            test['id'] = list(os.listdir(test_img_path))\n",
    "            #print('test',test)\n",
    "            test_ds = CassavaDataset(test, test_img_path, transforms=get_inference_transforms(), output_label=False)\n",
    "            #print('test_ds',test)\n",
    "            \n",
    "            tst_loader = torch.utils.data.DataLoader(\n",
    "                test_ds, \n",
    "                batch_size=cfg['valid_bs'],\n",
    "                num_workers=cfg['num_workers'],\n",
    "                shuffle=False,\n",
    "                pin_memory=False,\n",
    "            )\n",
    "            data_loader = tst_loader\n",
    "\n",
    "        device = torch.device(cfg['device'])\n",
    "        print(f'Num Class: {valid_df.class_id.nunique()}')\n",
    "        model = CassvaImgClassifier(cfg['model_arch'], valid_df.class_id.nunique()).to(device)\n",
    "        \n",
    "        # val_preds = []\n",
    "        # tst_preds = []\n",
    "        preds = []\n",
    "        \n",
    "        #for epoch in range(CFG['epochs']-3):\n",
    "        # for i, epoch in enumerate(cfg['used_epochs']):    \n",
    "        model_path = f'{model_dir}best_acc_{cfg[\"model_arch\"]}_fold{fold}.pt'\n",
    "        print(f'Loading {model_path}')\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(cfg['tta']):\n",
    "                preds += [cfg['weights'][0]/sum(cfg['weights'])/cfg['tta']*inference_one_epoch(model=model, data_loader=data_loader, device=device)]\n",
    "\n",
    "        preds = np.mean(preds, axis=0) \n",
    "        if is_local:\n",
    "            acc = (valid_df.class_id.values==np.argmax(preds, axis=1)).mean()\n",
    "            print('fold {} validation loss = {:.5f}'.format(fold, log_loss(valid_df.class_id.values, preds)))\n",
    "            print('fold {} validation accuracy = {:.5f}'.format(fold, acc))\n",
    "            accs.append(acc)\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    if not is_local:\n",
    "        sumfile = create_sub_df(test, preds)\n",
    "        sumfile.to_csv('./submission.csv',index=False)\n",
    "        !rm -r ./test/study/\n",
    "    else:\n",
    "        mean_acc = (sum(accs)/cfg[\"fold_num\"])*100.0\n",
    "        print(f'Mean Accuracy {mean_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037508,
     "end_time": "2021-06-07T14:35:58.167359",
     "exception": false,
     "start_time": "2021-06-07T14:35:58.129851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4 Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T14:35:58.261546Z",
     "iopub.status.busy": "2021-06-07T14:35:58.260850Z",
     "iopub.status.idle": "2021-06-07T14:45:46.385196Z",
     "shell.execute_reply": "2021-06-07T14:45:46.384561Z",
     "shell.execute_reply.started": "2021-06-07T13:23:17.963779Z"
    },
    "papermill": {
     "duration": 588.18003,
     "end_time": "2021-06-07T14:45:46.385447",
     "exception": false,
     "start_time": "2021-06-07T14:35:58.205417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on Validation dataset\n",
      "Inference fold 0 started\n",
      "Num Class: 4\n",
      "Loading ../models/exp1/best_acc_tf_efficientnet_b4_ns_fold0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:12<00:00,  3.07it/s]\n",
      "100%|██████████| 38/38 [00:11<00:00,  3.44it/s]\n",
      "100%|██████████| 38/38 [00:11<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 validation loss = 0.94210\n",
      "fold 0 validation accuracy = 0.64410\n",
      "Inference fold 1 started\n",
      "Num Class: 4\n",
      "Loading ../models/exp1/best_acc_tf_efficientnet_b4_ns_fold1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:10<00:00,  3.55it/s]\n",
      "100%|██████████| 38/38 [00:10<00:00,  3.55it/s]\n",
      "100%|██████████| 38/38 [00:10<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 validation loss = 0.95327\n",
      "fold 1 validation accuracy = 0.63501\n",
      "Inference fold 2 started\n",
      "Num Class: 4\n",
      "Loading ../models/exp1/best_acc_tf_efficientnet_b4_ns_fold2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:10<00:00,  3.54it/s]\n",
      "100%|██████████| 38/38 [00:10<00:00,  3.55it/s]\n",
      "100%|██████████| 38/38 [00:10<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2 validation loss = 0.93656\n",
      "fold 2 validation accuracy = 0.64410\n",
      "Inference fold 3 started\n",
      "Num Class: 4\n",
      "Loading ../models/exp1/best_acc_tf_efficientnet_b4_ns_fold3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:10<00:00,  3.55it/s]\n",
      "100%|██████████| 38/38 [00:10<00:00,  3.53it/s]\n",
      "100%|██████████| 38/38 [00:10<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 validation loss = 0.92083\n",
      "fold 3 validation accuracy = 0.65400\n",
      "Inference fold 4 started\n",
      "Num Class: 4\n",
      "Loading ../models/exp1/best_acc_tf_efficientnet_b4_ns_fold4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:11<00:00,  3.35it/s]\n",
      "100%|██████████| 38/38 [00:10<00:00,  3.52it/s]\n",
      "100%|██████████| 38/38 [00:10<00:00,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4 validation loss = 0.93776\n",
      "fold 4 validation accuracy = 0.63554\n",
      "Mean Accuracy 64.25492216664051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    cfg = {\n",
    "        'exp_id': 'exp1',\n",
    "        'train_csv_name':'train_classification_fold_v1.csv',\n",
    "        'fold_num': 5,\n",
    "        'seed': 719,\n",
    "        #'model_arch': 'tf_efficientnet_b7',\n",
    "        'model_arch': 'tf_efficientnet_b4_ns',\n",
    "        'img_size': 512,\n",
    "        'epochs': 100,\n",
    "        'train_bs': 14,\n",
    "        'valid_bs': 32,\n",
    "        'T_0': 10,\n",
    "        'lr': 1e-6,\n",
    "        'min_lr': 1e-6,\n",
    "        'weight_decay':1e-6,\n",
    "        'num_workers': 4,\n",
    "        'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "        'verbose_step': 1,\n",
    "        'device': 'cuda:0',\n",
    "        'tta': 3,\n",
    "        'used_epochs': [53,55,56,59],\n",
    "        'weights': [1,1,1,1]\n",
    "    }\n",
    "\n",
    "    inference(cfg, is_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold 0 validation loss = 0.94095\n",
    "# fold 0 validation accuracy = 0.64162"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1189.20328,
   "end_time": "2021-06-07T14:46:22.000765",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-07T14:26:32.797485",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "26f7c905a79a4b38a4817fdd42c575e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3d6a3edbe5c9411eaaf1a83e8ce2c783": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b2a8f463c66e475b8ee4c96f9a2e16bc",
       "placeholder": "​",
       "style": "IPY_MODEL_e3bbb7682f3b4cddbb222bc77968b111",
       "value": ""
      }
     },
     "558e3be1b4bc44e1953c617e5e33f1d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "66bc9cf12ef44e8489c27301106ec17f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6a8774dc00134c5baedba1d8d180b7d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "870c29d3d5e84155ba33fbb69e2df92c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "88058e104fca43178735a1578cad387e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3d6a3edbe5c9411eaaf1a83e8ce2c783",
        "IPY_MODEL_e0dee6ee614947bba0f593aeec17cf52",
        "IPY_MODEL_b62da25c98b3426da543c20c6635be00"
       ],
       "layout": "IPY_MODEL_26f7c905a79a4b38a4817fdd42c575e7"
      }
     },
     "b2a8f463c66e475b8ee4c96f9a2e16bc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b62da25c98b3426da543c20c6635be00": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_870c29d3d5e84155ba33fbb69e2df92c",
       "placeholder": "​",
       "style": "IPY_MODEL_558e3be1b4bc44e1953c617e5e33f1d1",
       "value": " 2475/? [08:02&lt;00:00,  4.58it/s]"
      }
     },
     "e0dee6ee614947bba0f593aeec17cf52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6a8774dc00134c5baedba1d8d180b7d0",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_66bc9cf12ef44e8489c27301106ec17f",
       "value": 1
      }
     },
     "e3bbb7682f3b4cddbb222bc77968b111": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}