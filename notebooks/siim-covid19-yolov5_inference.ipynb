{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "piano-spare",
   "metadata": {
    "papermill": {
     "duration": 0.017995,
     "end_time": "2021-06-27T08:54:00.790258",
     "exception": false,
     "start_time": "2021-06-27T08:54:00.772263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "https://www.kaggle.com/laxmikantnishad/covid-19-2-para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "revised-exception",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T08:54:00.834314Z",
     "iopub.status.busy": "2021-06-27T08:54:00.833187Z",
     "iopub.status.idle": "2021-06-27T08:54:00.835578Z",
     "shell.execute_reply": "2021-06-27T08:54:00.835957Z",
     "shell.execute_reply.started": "2021-06-27T05:55:30.011742Z"
    },
    "papermill": {
     "duration": 0.029118,
     "end_time": "2021-06-27T08:54:00.836159",
     "exception": false,
     "start_time": "2021-06-27T08:54:00.807041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_local=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "joined-milwaukee",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-06-27T08:54:00.880655Z",
     "iopub.status.busy": "2021-06-27T08:54:00.880104Z",
     "iopub.status.idle": "2021-06-27T08:55:07.449269Z",
     "shell.execute_reply": "2021-06-27T08:55:07.448742Z",
     "shell.execute_reply.started": "2021-06-27T05:55:30.020227Z"
    },
    "papermill": {
     "duration": 66.596433,
     "end_time": "2021-06-27T08:55:07.449401",
     "exception": false,
     "start_time": "2021-06-27T08:54:00.852968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Downloading and Extracting Packages\r\n",
      "######################################################################## | 100% \r\n",
      "Preparing transaction: - \b\bdone\r\n",
      "Verifying transaction: | \b\bdone\r\n",
      "Executing transaction: - \b\b\\ \b\bdone\r\n",
      "\r\n",
      "Downloading and Extracting Packages\r\n",
      "######################################################################## | 100% \r\n",
      "Preparing transaction: - \b\bdone\r\n",
      "Verifying transaction: | \b\bdone\r\n",
      "Executing transaction: - \b\b\\ \b\b| \b\bdone\r\n",
      "\r\n",
      "Downloading and Extracting Packages\r\n",
      "######################################################################## | 100% \r\n",
      "Preparing transaction: - \b\bdone\r\n",
      "Verifying transaction: | \b\bdone\r\n",
      "Executing transaction: - \b\bdone\r\n",
      "\r\n",
      "Downloading and Extracting Packages\r\n",
      "######################################################################## | 100% \r\n",
      "Preparing transaction: - \b\bdone\r\n",
      "Verifying transaction: | \b\bdone\r\n",
      "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\r\n",
      "\r\n",
      "Downloading and Extracting Packages\r\n",
      "######################################################################## | 100% \r\n",
      "Preparing transaction: - \b\bdone\r\n",
      "Verifying transaction: | \b\bdone\r\n",
      "Executing transaction: - \b\bdone\r\n",
      "\r\n",
      "Downloading and Extracting Packages\r\n",
      "######################################################################## | 100% \r\n",
      "Preparing transaction: - \b\bdone\r\n",
      "Verifying transaction: | \b\bdone\r\n",
      "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\r\n"
     ]
    }
   ],
   "source": [
    "if not is_local:\n",
    "    !conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n",
    "    !conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n",
    "    !conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n",
    "    !conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n",
    "    !conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n",
    "    !conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y\n",
    "#     !pip install pylibjpeg \n",
    "    #pylibjpeg-libjpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "promising-cliff",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-27T08:55:07.518712Z",
     "iopub.status.busy": "2021-06-27T08:55:07.518156Z",
     "iopub.status.idle": "2021-06-27T08:55:07.526240Z",
     "shell.execute_reply": "2021-06-27T08:55:07.525828Z",
     "shell.execute_reply.started": "2021-06-27T05:56:28.243408Z"
    },
    "papermill": {
     "duration": 0.044019,
     "end_time": "2021-06-27T08:55:07.526349",
     "exception": false,
     "start_time": "2021-06-27T08:55:07.482330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-family",
   "metadata": {
    "papermill": {
     "duration": 0.031896,
     "end_time": "2021-06-27T08:55:07.590265",
     "exception": false,
     "start_time": "2021-06-27T08:55:07.558369",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "（1）dcm to .png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spatial-massage",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T08:55:07.661461Z",
     "iopub.status.busy": "2021-06-27T08:55:07.660252Z",
     "iopub.status.idle": "2021-06-27T08:55:07.662573Z",
     "shell.execute_reply": "2021-06-27T08:55:07.662942Z",
     "shell.execute_reply.started": "2021-06-27T05:56:28.262970Z"
    },
    "papermill": {
     "duration": 0.040459,
     "end_time": "2021-06-27T08:55:07.663073",
     "exception": false,
     "start_time": "2021-06-27T08:55:07.622614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_xray(path, voi_lut = True, fix_monochrome = True):\n",
    "    import pydicom\n",
    "    from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "#     import pylibjpeg\n",
    "    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n",
    "    dicom = pydicom.read_file(path)\n",
    "    \n",
    "    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n",
    "    # \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        data = dicom.pixel_array\n",
    "               \n",
    "    # depending on this value, X-ray may look inverted - fix that:\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        data = np.amax(data) - data\n",
    "        \n",
    "    data = data - np.min(data)\n",
    "    data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "        \n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "coral-imaging",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T08:55:07.731707Z",
     "iopub.status.busy": "2021-06-27T08:55:07.731153Z",
     "iopub.status.idle": "2021-06-27T08:55:07.734889Z",
     "shell.execute_reply": "2021-06-27T08:55:07.734477Z",
     "shell.execute_reply.started": "2021-06-27T05:56:28.280248Z"
    },
    "papermill": {
     "duration": 0.039795,
     "end_time": "2021-06-27T08:55:07.734992",
     "exception": false,
     "start_time": "2021-06-27T08:55:07.695197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n",
    "    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image\n",
    "    im = Image.fromarray(array)\n",
    "    \n",
    "    if keep_ratio:\n",
    "        im.thumbnail((size, size), resample)\n",
    "    else:\n",
    "        im = im.resize((size, size), resample)\n",
    "    \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "exempt-vehicle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T08:55:07.804690Z",
     "iopub.status.busy": "2021-06-27T08:55:07.803931Z",
     "iopub.status.idle": "2021-06-27T08:55:07.806525Z",
     "shell.execute_reply": "2021-06-27T08:55:07.806032Z",
     "shell.execute_reply.started": "2021-06-27T05:56:28.295875Z"
    },
    "papermill": {
     "duration": 0.039856,
     "end_time": "2021-06-27T08:55:07.806641",
     "exception": false,
     "start_time": "2021-06-27T08:55:07.766785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_test_images(img_size=512, split = 'test'):\n",
    "    save_dir = f'./{split}/'\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    save_dir = f'./{split}/study/'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):\n",
    "        for file in filenames:\n",
    "            # set keep_ratio=True to have original aspect ratio\n",
    "            xray = read_xray(os.path.join(dirname, file))\n",
    "            im = resize(xray, size=img_size)  \n",
    "            study = dirname.split('/')[-2] + '_study.png'\n",
    "            #study = dirname.split('/')[-2] + '_study'\n",
    "            im.save(os.path.join(save_dir, study))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mineral-puzzle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T08:55:07.874427Z",
     "iopub.status.busy": "2021-06-27T08:55:07.873739Z",
     "iopub.status.idle": "2021-06-27T08:55:08.504039Z",
     "shell.execute_reply": "2021-06-27T08:55:08.503560Z",
     "shell.execute_reply.started": "2021-06-27T05:56:28.310468Z"
    },
    "papermill": {
     "duration": 0.665638,
     "end_time": "2021-06-27T08:55:08.504152",
     "exception": false,
     "start_time": "2021-06-27T08:55:07.838514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access './test/study': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./test/study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "engaging-analysis",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T08:55:08.576974Z",
     "iopub.status.busy": "2021-06-27T08:55:08.576212Z",
     "iopub.status.idle": "2021-06-27T08:55:08.578996Z",
     "shell.execute_reply": "2021-06-27T08:55:08.578595Z",
     "shell.execute_reply.started": "2021-06-27T05:56:29.063727Z"
    },
    "papermill": {
     "duration": 0.04089,
     "end_time": "2021-06-27T08:55:08.579102",
     "exception": false,
     "start_time": "2021-06-27T08:55:08.538212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys; \n",
    "\n",
    "package_paths = [\n",
    "    '../input/image-fmix/FMix-master'                            #FMix是一种数据增强方法（最近比较火的一种）\n",
    "]\n",
    "\n",
    "if not is_local:\n",
    "    package_paths.append('../input/pytorch-image-models/pytorch-image-models-master') #导入pytorch模型\n",
    "\n",
    "for pth in package_paths:\n",
    "    sys.path.append(pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "massive-absolute",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T08:55:08.660492Z",
     "iopub.status.busy": "2021-06-27T08:55:08.659671Z",
     "iopub.status.idle": "2021-06-27T08:55:11.732711Z",
     "shell.execute_reply": "2021-06-27T08:55:11.732183Z",
     "shell.execute_reply.started": "2021-06-27T05:56:29.075453Z"
    },
    "papermill": {
     "duration": 3.115599,
     "end_time": "2021-06-27T08:55:11.732855",
     "exception": false,
     "start_time": "2021-06-27T08:55:08.617256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import cv2\n",
    "from skimage import io\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import timm\n",
    "import sklearn\n",
    "import warnings\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "# import pydicom\n",
    "\n",
    "\n",
    "from fmix import sample_mask, make_low_freq_image, binarise_mask\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "\n",
    "# import pydicom\n",
    "# from pydicom.pixel_data_handlers.util import apply_voi_lut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "skilled-providence",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T08:55:12.042765Z",
     "iopub.status.busy": "2021-06-27T08:55:12.042145Z",
     "iopub.status.idle": "2021-06-27T08:55:12.045907Z",
     "shell.execute_reply": "2021-06-27T08:55:12.045442Z",
     "shell.execute_reply.started": "2021-06-27T05:56:30.539341Z"
    },
    "papermill": {
     "duration": 0.052452,
     "end_time": "2021-06-27T08:55:12.046011",
     "exception": false,
     "start_time": "2021-06-27T08:55:11.993559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    #print(im_rgb)\n",
    "    return im_rgb\n",
    "\n",
    "#img = get_img('../input/siim-covid19-detection/test/00188a671292/3eb5a506ccf3/3dcdfc352a06.dcm')\n",
    "#plt.imshow(img)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "essential-enough",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T08:55:12.991792Z",
     "iopub.status.busy": "2021-06-27T08:55:12.991180Z",
     "iopub.status.idle": "2021-06-27T08:55:12.994835Z",
     "shell.execute_reply": "2021-06-27T08:55:12.994316Z",
     "shell.execute_reply.started": "2021-06-27T05:56:31.020587Z"
    },
    "papermill": {
     "duration": 0.041292,
     "end_time": "2021-06-27T08:55:12.994936",
     "exception": false,
     "start_time": "2021-06-27T08:55:12.953644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_sub_df(test, tst_preds):\n",
    "    sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\n",
    "    for i in range(len(test)):\n",
    "        for j in range(len(test)):\n",
    "            a = test.loc[i,'id'].split('.')[0]\n",
    "            b = sub_df.loc[j,'id']\n",
    "            if a==b:\n",
    "                negative, typical, indeterminate, atypical = str(tst_preds[i][0]),str(tst_preds[i][1]),str(tst_preds[i][2]),str(tst_preds[i][3]),\n",
    "                sub_df.loc[j,'PredictionString'] = f'negative {negative} 0 0 1 1 typical {typical} 0 0 1 1 indeterminate {indeterminate} 0 0 1 1 atypical {atypical} 0 0 1 1'\n",
    "    return sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "overall-version",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T08:55:13.083297Z",
     "iopub.status.busy": "2021-06-27T08:55:13.061811Z",
     "iopub.status.idle": "2021-06-27T08:55:13.087795Z",
     "shell.execute_reply": "2021-06-27T08:55:13.088167Z",
     "shell.execute_reply.started": "2021-06-27T05:56:31.041368Z"
    },
    "papermill": {
     "duration": 0.060954,
     "end_time": "2021-06-27T08:55:13.088283",
     "exception": false,
     "start_time": "2021-06-27T08:55:13.027329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(cfg, is_local, is_ensemble=True):\n",
    "    if is_local:\n",
    "        print('Inference on Validation dataset')\n",
    "    else:\n",
    "        print('Inference on Test dataset')\n",
    "\n",
    "    seed_everything(cfg['seed'])\n",
    "    # folds = StratifiedKFold(n_splits=CFG['fold_num']).split(np.arange(train_study.shape[0]), train_study.label.values)\n",
    "\n",
    "    if is_local:\n",
    "        model_dir = f'../models/{cfg[\"exp_id\"]}/'\n",
    "        train_img_path = '../input/siimcovid19-512-img-png-600-study-png/study/'\n",
    "        test_img_path = './test/study/'\n",
    "        train_csv_path = f'../input/siim_covid19_train/{cfg[\"train_csv_name\"]}'\n",
    "        train = pd.read_csv(train_csv_path)\n",
    "    else:\n",
    "        model_dir = f'../input/siim-covid19-studyclass-models/{cfg[\"exp_id\"]}/'\n",
    "        train_img_path = '../input/siimcovid19-512-img-png-600-study-png/study/'\n",
    "        test_img_path = './test/study/'\n",
    "        train_csv_path = f'../input/siim-covid19-train/{cfg[\"train_csv_name\"]}'\n",
    "        prepare_test_images()\n",
    "        test = pd.DataFrame()\n",
    "        test['id'] = list(os.listdir(test_img_path))\n",
    "        # df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\n",
    "        # if df.shape[0] == 2477:\n",
    "        #     fast_sub = True\n",
    "        #     fast_df = pd.DataFrame(([['00086460a852_study', 'negative 1 0 0 1 1'], \n",
    "        #                         ['000c9c05fd14_study', 'negative 1 0 0 1 1'], \n",
    "        #                         ['65761e66de9f_image', 'none 1 0 0 1 1'], \n",
    "        #                         ['51759b5579bc_image', 'none 1 0 0 1 1']]), \n",
    "        #                     columns=['id', 'PredictionString'])\n",
    "        # else:\n",
    "        #     fast_sub = False\n",
    "    \n",
    "    accs = []\n",
    "    test_preds_all = 0\n",
    "    # for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "    for idx, fold in enumerate(range(cfg['fold_num'])):\n",
    "        # train_df = train[train['fold'] != fold]\n",
    "        # we'll train fold 0 first\n",
    "#         if fold > 0:\n",
    "#             break \n",
    "\n",
    "        print('Inference fold {} started'.format(fold))\n",
    "\n",
    "        if is_local:\n",
    "            valid_df = train[train['fold'] == fold]\n",
    "            # valid_ = train_study.loc[val_idx,:].reset_index(drop=True)\n",
    "            #print('valid_',valid_)\n",
    "            valid_ds = CassavaDataset(valid_df, train_img_path, transforms=get_inference_transforms(), output_label=False, mode='valid')\n",
    "            val_loader = torch.utils.data.DataLoader(\n",
    "                valid_ds, \n",
    "                batch_size=cfg['valid_bs'],\n",
    "                num_workers=cfg['num_workers'],\n",
    "                shuffle=False,\n",
    "                pin_memory=False,\n",
    "            )\n",
    "            data_loader = val_loader\n",
    "        else:\n",
    "#             test = pd.DataFrame()\n",
    "#             test['id'] = list(os.listdir(test_img_path))\n",
    "            #print('test',test)\n",
    "            test_ds = CassavaDataset(test, test_img_path, transforms=get_inference_transforms(), output_label=False, mode='test')\n",
    "            #print('test_ds',test)\n",
    "            \n",
    "            tst_loader = torch.utils.data.DataLoader(\n",
    "                test_ds, \n",
    "                batch_size=cfg['valid_bs'],\n",
    "                num_workers=cfg['num_workers'],\n",
    "                shuffle=False,\n",
    "                pin_memory=False,\n",
    "            )\n",
    "            data_loader = tst_loader\n",
    "\n",
    "        device = torch.device(cfg['device'])\n",
    "#         valid_df.class_id.nunique()\n",
    "        print(f'Num Class: {cfg[\"num_classes\"]}')\n",
    "        model = CassvaImgClassifier(cfg['model_arch'], cfg[\"num_classes\"]).to(device)\n",
    "        \n",
    "\n",
    "        preds = []\n",
    "#         ensemble_preds = []\n",
    "        \n",
    "        #for epoch in range(CFG['epochs']-3):\n",
    "        # for i, epoch in enumerate(cfg['used_epochs']):    \n",
    "        model_path = f'{model_dir}best_acc_{cfg[\"model_arch\"]}_fold{fold}.pt'\n",
    "        print(f'Loading {model_path}')\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(cfg['tta']):\n",
    "#                 if is_ensemble:\n",
    "#                     ensemble_preds += [cfg['weights'][0]/sum(cfg['weights'])/cfg['tta']*inference_one_epoch(model=model, data_loader=data_loader, device=device)]\n",
    "#                 else:\n",
    "                preds += [cfg['weights'][0]/sum(cfg['weights'])/cfg['tta']*inference_one_epoch(model=model, data_loader=data_loader, device=device)]\n",
    "#         if is_ensemble:\n",
    "#             ensemble_preds = np.mean(ensemble_preds, axis=0)\n",
    "#         else:\n",
    "        preds = np.mean(preds, axis=0)\n",
    "    \n",
    "        if is_ensemble:\n",
    "            test_preds_all += preds\n",
    "            \n",
    "        if is_local:\n",
    "            acc = (valid_df.class_id.values==np.argmax(preds, axis=1)).mean()\n",
    "            print('fold {} validation loss = {:.5f}'.format(fold, log_loss(valid_df.class_id.values, preds)))\n",
    "            print('fold {} validation accuracy = {:.5f}'.format(fold, acc))\n",
    "            accs.append(acc)\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    if not is_local:\n",
    "        if is_ensemble:\n",
    "            test_preds_all /= cfg['fold_num']\n",
    "            sumfile = create_sub_df(test, test_preds_all)\n",
    "        else:\n",
    "            sumfile = create_sub_df(test, preds)\n",
    "        sumfile.to_csv('./submission.csv',index=False)\n",
    "        return sumfile\n",
    "    else:\n",
    "        mean_acc = (sum(accs)/cfg[\"fold_num\"])*100.0\n",
    "        print(f'Mean Accuracy {mean_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-command",
   "metadata": {
    "papermill": {
     "duration": 0.032848,
     "end_time": "2021-06-27T08:55:13.154121",
     "exception": false,
     "start_time": "2021-06-27T08:55:13.121273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-reynolds",
   "metadata": {
    "papermill": {
     "duration": 0.032004,
     "end_time": "2021-06-27T08:55:13.218351",
     "exception": false,
     "start_time": "2021-06-27T08:55:13.186347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4 Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "general-senegal",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T08:55:13.288546Z",
     "iopub.status.busy": "2021-06-27T08:55:13.288017Z",
     "iopub.status.idle": "2021-06-27T09:10:35.333972Z",
     "shell.execute_reply": "2021-06-27T09:10:35.333470Z",
     "shell.execute_reply.started": "2021-06-27T05:56:31.073489Z"
    },
    "papermill": {
     "duration": 922.08347,
     "end_time": "2021-06-27T09:10:35.334113",
     "exception": false,
     "start_time": "2021-06-27T08:55:13.250643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on Test dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2475it [08:37,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference fold 0 started\n",
      "Num Class: 4\n",
      "Loading ../input/siim-covid19-studyclass-models/exp1/best_acc_tf_efficientnet_b4_ns_fold0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:25<00:00,  1.46it/s]\n",
      "100%|██████████| 38/38 [00:22<00:00,  1.67it/s]\n",
      "100%|██████████| 38/38 [00:24<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference fold 1 started\n",
      "Num Class: 4\n",
      "Loading ../input/siim-covid19-studyclass-models/exp1/best_acc_tf_efficientnet_b4_ns_fold1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:23<00:00,  1.61it/s]\n",
      "100%|██████████| 38/38 [00:23<00:00,  1.62it/s]\n",
      "100%|██████████| 38/38 [00:23<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference fold 2 started\n",
      "Num Class: 4\n",
      "Loading ../input/siim-covid19-studyclass-models/exp1/best_acc_tf_efficientnet_b4_ns_fold2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:23<00:00,  1.63it/s]\n",
      "100%|██████████| 38/38 [00:24<00:00,  1.56it/s]\n",
      "100%|██████████| 38/38 [00:23<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference fold 3 started\n",
      "Num Class: 4\n",
      "Loading ../input/siim-covid19-studyclass-models/exp1/best_acc_tf_efficientnet_b4_ns_fold3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:23<00:00,  1.61it/s]\n",
      "100%|██████████| 38/38 [00:23<00:00,  1.63it/s]\n",
      "100%|██████████| 38/38 [00:23<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference fold 4 started\n",
      "Num Class: 4\n",
      "Loading ../input/siim-covid19-studyclass-models/exp1/best_acc_tf_efficientnet_b4_ns_fold4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:23<00:00,  1.60it/s]\n",
      "100%|██████████| 38/38 [00:22<00:00,  1.66it/s]\n",
      "100%|██████████| 38/38 [00:23<00:00,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    cfg = {\n",
    "        'exp_id': 'exp1',\n",
    "        'train_csv_name':'train_classification_fold_v1.csv',\n",
    "        'fold_num': 5,\n",
    "        'num_classes': 4,\n",
    "        'seed': 719,\n",
    "        #'model_arch': 'tf_efficientnet_b7',\n",
    "        'model_arch': 'tf_efficientnet_b4_ns',\n",
    "        'img_size': 512,\n",
    "        'epochs': 100,\n",
    "        'train_bs': 14,\n",
    "        'valid_bs': 32,\n",
    "        'T_0': 10,\n",
    "        'lr': 1e-6,\n",
    "        'min_lr': 1e-6,\n",
    "        'weight_decay':1e-6,\n",
    "        'num_workers': 4,\n",
    "        'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "        'verbose_step': 1,\n",
    "        'device': 'cuda:0',\n",
    "        'tta': 3,\n",
    "        'used_epochs': [53,55,56,59],\n",
    "        'weights': [1,1,1,1]\n",
    "    }\n",
    "\n",
    "    inference(cfg, is_local, is_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "confused-edwards",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-27T09:10:36.351956Z",
     "iopub.status.busy": "2021-06-27T09:10:36.351383Z",
     "iopub.status.idle": "2021-06-27T09:10:36.355377Z",
     "shell.execute_reply": "2021-06-27T09:10:36.354968Z"
    },
    "papermill": {
     "duration": 0.515243,
     "end_time": "2021-06-27T09:10:36.355488",
     "exception": false,
     "start_time": "2021-06-27T09:10:35.840245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fold 0 validation loss = 0.94095\n",
    "# fold 0 validation accuracy = 0.64162"
   ]
  },
  {
   "source": [
    "## YOLOv5 Inference"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "# import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta[meta['split'] == 'test']\n",
    "if fast_sub:\n",
    "    test_df = fast_df.copy()\n",
    "else:\n",
    "    test_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')\n",
    "test_df = df[study_len:].reset_index(drop=True) \n",
    "meta['image_id'] = meta['image_id'] + '_image'\n",
    "meta.columns = ['id', 'dim0', 'dim1', 'split']\n",
    "test_df = pd.merge(test_df, meta, on = 'id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo2voc(image_height, image_width, bboxes):\n",
    "    \"\"\"\n",
    "    yolo => [xmid, ymid, w, h] (normalized)\n",
    "    voc  => [x1, y1, x2, y1]\n",
    "\n",
    "    \"\"\" \n",
    "    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
    "\n",
    "    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n",
    "    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n",
    "\n",
    "    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n",
    "    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n",
    "\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 512 #1024, 256, 'original'\n",
    "test_dir = f'./{split}/study' #f'/kaggle/tmp/{split}/image'\n",
    "weights_dir = '/kaggle/input/siim-cov19-yolov5-train/yolov5/runs/train/exp/weights/best.pt'\n",
    "\n",
    "# import torch\n",
    "#from IPython.display import Image, clear_output  # to display images\n",
    "\n",
    "#clear_output()\n",
    "#print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))\n",
    "\n",
    "\n",
    "!python detect.py --weights $weights_dir\\\n",
    "                    --img 512\\\n",
    "                    --conf 0.001\\\n",
    "                    --iou 0.5\\\n",
    "                    --source $test_dir\\\n",
    "                    --save-txt --save-conf --exist-ok\n",
    "\n",
    "\n",
    "image_ids = []\n",
    "PredictionStrings = []\n",
    "\n",
    "for file_path in tqdm(glob('runs/detect/exp/labels/*.txt')):\n",
    "    image_id = file_path.split('/')[-1].split('.')[0]\n",
    "    w, h = test_df.loc[test_df.id==image_id,['dim1', 'dim0']].values[0]\n",
    "    f = open(file_path, 'r')\n",
    "    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n",
    "    data = data[:, [0, 5, 1, 2, 3, 4]]\n",
    "    bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 12).astype(str))\n",
    "    for idx in range(len(bboxes)):\n",
    "        bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n",
    "    image_ids.append(image_id)\n",
    "    PredictionStrings.append(' '.join(bboxes))\n",
    "\n",
    "\n",
    "pred_df = pd.DataFrame({'id':image_ids,\n",
    "                        'PredictionString':PredictionStrings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop(['PredictionString'], axis=1)\n",
    "sub_df = pd.merge(test_df, pred_df, on = 'id', how = 'left').fillna(\"none 1 0 0 1 1\")\n",
    "sub_df = sub_df[['id', 'PredictionString']]\n",
    "for i in range(sub_df.shape[0]):\n",
    "    if sub_df.loc[i,'PredictionString'] == \"none 1 0 0 1 1\":\n",
    "        continue\n",
    "    sub_df_split = sub_df.loc[i,'PredictionString'].split()\n",
    "    sub_df_list = []\n",
    "    for j in range(int(len(sub_df_split) / 6)):\n",
    "        sub_df_list.append('opacity')\n",
    "        sub_df_list.append(sub_df_split[6 * j + 1])\n",
    "        sub_df_list.append(sub_df_split[6 * j + 2])\n",
    "        sub_df_list.append(sub_df_split[6 * j + 3])\n",
    "        sub_df_list.append(sub_df_split[6 * j + 4])\n",
    "        sub_df_list.append(sub_df_split[6 * j + 5])\n",
    "    sub_df.loc[i,'PredictionString'] = ' '.join(sub_df_list)\n",
    "sub_df['none'] = df_2class['none'] \n",
    "for i in range(sub_df.shape[0]):\n",
    "    if sub_df.loc[i,'PredictionString'] != 'none 1 0 0 1 1':\n",
    "        sub_df.loc[i,'PredictionString'] = sub_df.loc[i,'PredictionString'] + ' none ' + str(sub_df.loc[i,'none']) + ' 0 0 1 1'\n",
    "sub_df = sub_df[['id', 'PredictionString']]   \n",
    "df_study = df_study[:study_len]\n",
    "df_study = df_study.append(sub_df).reset_index(drop=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1004.178553,
   "end_time": "2021-06-27T09:10:38.652642",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-27T08:53:54.474089",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}