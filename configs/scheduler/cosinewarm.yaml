# @package _global_
scheduler:
  class_name: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
  step: step
  monitor: ${train.monitor}
  params:
    T_0: 150
    T_mult: 2 #3
    eta_min: 0
    last_epoch: -1